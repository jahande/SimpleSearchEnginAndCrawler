Harmonic mean - Wikipedia, the free encyclopedia Harmonic mean From Wikipedia, the free encyclopedia Jump to: navigation, search In mathematics, the harmonic mean (sometimes called the subcontrary mean) is one of several kinds of average. Typically, it is appropriate for situations when the average of rates is desired. The harmonic mean H of the positive real numbers x1, x2, ..., xn > 0 is defined to be From the third formula in the above equation it is more apparent that the harmonic mean is related to the arithmetic mean and geometric mean. Equivalently, the harmonic mean is the reciprocal of the arithmetic mean of the reciprocals. As a simple example, the harmonic mean of 1, 2, and 4 is Contents 1 Relationship with other means 2 Weighted harmonic mean 3 Examples 3.1 In physics 3.2 In other sciences 3.3 In finance 3.4 In geometry 3.5 In trigonometry 4 Harmonic mean of two numbers 5 See also 6 References 7 External links Relationship with other means[edit] A geometric construction of the three Pythagorean means of two numbers, a and b. Harmonic mean is denoted by H in purple color. The Q denotes a fourth mean, the quadratic mean. The harmonic mean is one of the three Pythagorean means. For all positive data sets containing at least one pair of nonequal values, the harmonic mean is always the least of the three means, while the arithmetic mean is always the greatest of the three and the geometric mean is always in between. (If all values in a nonempty dataset are equal, the three means are always equal to one another; e.g. the harmonic, geometric, and arithmetic means of {2, 2, 2} are all 2.) It is the special case M?1 of the power mean. Since the harmonic mean of a list of numbers tends strongly toward the least elements of the list, it tends (compared to the arithmetic mean) to mitigate the impact of large outliers and aggravate the impact of small ones. The arithmetic mean is often mistakenly used in places calling for the harmonic mean.[1] In the speed example below for instance the arithmetic mean 50 is incorrect, and too big. The harmonic mean is related to the other Pythagorean means, as seen in the third formula in the above equation. This is noticed if we interpret the denominator to be the arithmetic mean of the product of numbers n times but each time we omit the jth term. That is, for the first term we multiply all n numbers but omit the first, for the second we multiply all n numbers but omit the second and so on. The numerator, excluding the n, which goes with the arithmetic mean, is the geometric mean to the power n. Thus the nth harmonic mean is related to the nth geometric and arithmetic means. If a set of non-identical numbers is subjected to a mean-preserving spread — that is, two or more elements of the set are "spread apart" from each other while leaving the arithmetic mean unchanged — then the harmonic mean always decreases.[2] Weighted harmonic mean[edit] If a set of weights , ..., is associated to the dataset , ..., , the weighted harmonic mean is defined by The harmonic mean as defined is the special case where all of the weights are equal to 1, and is equivalent to any weighted harmonic mean where all weights are equal Examples[edit] In physics[edit] In certain situations, especially many situations involving rates and ratios, the harmonic mean provides the truest average. For instance, if a vehicle travels a certain distance at a speed x (e.g. 60 kilometres per hour) and then the same distance again at a speed y (e.g. 40 kilometres per hour), then its average speed is the harmonic mean of x and y (48 kilometres per hour), and its total travel time is the same as if it had traveled the whole distance at that average speed. However, if the vehicle travels for a certain amount of time at a speed x and then the same amount of time at a speed y, then its average speed is the arithmetic mean of x and y, which in the above example is 50 kilometres per hour. The same principle applies to more than two segments: given a series of sub-trips at different speeds, if each sub-trip covers the same distance, then the average speed is the harmonic mean of all the sub-trip speeds, and if each sub-trip takes the same amount of time, then the average speed is the arithmetic mean of all the sub-trip speeds. (If neither is the case, then a weighted harmonic mean or weighted arithmetic mean is needed.) Similarly, if one connects two electrical resistors in parallel, one having resistance x (e.g. 60?) and one having resistance y (e.g. 40?), then the effect is the same as if one had used two resistors with the same resistance, both equal to the harmonic mean of x and y (48?): the equivalent resistance in either case is 24? (one-half of the harmonic mean). However, if one connects the resistors in series, then the average resistance is the arithmetic mean of x and y (with total resistance equal to the sum of x and y). And, as with previous example, the same principle applies when more than two resistors are connected, provided that all are in parallel or all are in series. In other sciences[edit] In computer science, specifically information retrieval and machine learning, the harmonic mean of the precision and the recall is often used as an aggregated performance score for the evaluation of algorithms and systems: the F-score (or F-measure). An interesting consequence arises from basic algebra in problems of working together. As an example, if a gas-powered pump can drain a pool in 4 hours and a battery-powered pump can drain the same pool in 6 hours, then it will take both pumps (6 · 4)/(6 + 4), which is equal to 2.4 hours, to drain the pool together. Interestingly, this is one-half of the harmonic mean of 6 and 4. In hydrology the harmonic mean is used to average hydraulic conductivity values for flow that is perpendicular to layers (e.g. geologic or soil) while flow parallel to layers uses the arithmetic mean. This apparent difference in averaging is explained by the fact that hydrology uses conductivity, which is the inverse of resistivity. In sabermetrics, the Power-speed number of a player is the harmonic mean of his home run and stolen base totals. In population genetics the harmonic mean is used when calculating the effects of fluctuations in generation size on the effective breeding population. This is to take into account the fact that a very small generation is effectively like a bottleneck and means that a very small number of individuals are contributing disproportionately to the gene pool which can result in higher levels of inbreeding. When considering fuel economy in automobiles two measures are commonly used – miles per gallon (mpg), and litres per 100 km. As the dimensions of these quantities are the inverse of each other (one is distance per volume, the other volume per distance) when taking the mean value of the fuel-economy of a range of cars one measure will produce the harmonic mean of the other – i.e. converting the mean value of fuel economy expressed in litres per 100 km to miles per gallon will produce the harmonic mean of the fuel economy expressed in miles-per-gallon. In finance[edit] The harmonic mean is the preferable method for averaging multiples, such as the price/earning ratio, in which price is in the numerator. If these ratios are averaged using an arithmetic mean (a common error), high data points are given greater weights than low data points. The harmonic mean, on the other hand, gives equal weight to each data point.[3] In geometry[edit] In any triangle, the radius of the incircle is one-third the harmonic mean of the altitudes. For any point P on the minor arc BC of the circumcircle of an equilateral triangle ABC, with distances q and t from B and C respectively, and with the intersection of PA and BC being at a distance y from point P, we have that y is half the harmonic mean of q and t.[4] In a right triangle with legs a and b and altitude h from the hypotenuse to the right angle, h2 is half the harmonic mean of a2 and b2.[5][6] Let t and s (t > s) be the sides of the two inscribed squares in a right triangle with hypotenuse c. Then s2 equals half the harmonic mean of c2 and t2. Let a trapezoid have vertices A, B, C, and D in sequence and have parallel sides AB and CD. Let E be the intersection of the diagonals, and let F be on side DA and G be on side BC such that FEG is parallel to AB and CD. Then FG is the harmonic mean of AB and DC. (This is provable using similar triangles.) Crossed ladders. h is half the harmonic mean of A and B In the crossed ladders problem, two ladders lie oppositely across an alley, each with feet at the base of one sidewall, with one leaning against a wall at height A and the other leaning against the opposite wall at height B, as shown. The ladders cross at a height of h above the alley floor. Then h is half the harmonic mean of A and B. This result still holds if the walls are slanted but still parallel and the "heights" A, B, and h are measured as distances from the floor along lines parallel to the walls. In an ellipse, the semi-latus rectum (the distance from a focus to the ellipse along a line parallel to the minor axis) is the harmonic mean of the maximum and minimum distances of the ellipse from a focus. In trigonometry[edit] In the case of the double-angle tangent identity, if the tangent of an angle A is given as a/b, then the tangent of 2A is the product of (1) the harmonic mean of the numerator and denominator of tan A and (2) the reciprocal of (the denominator minus the numerator of tan A). In general the double-angle formula can be written as if and and are real numbers. For example, if then the most familiar form of the double-angle formula is but this can also be written as Harmonic mean of two numbers[edit] For the special case of just two numbers and , the harmonic mean can be written In this special case, the harmonic mean is related to the arithmetic mean and the geometric mean by So , meaning the two numbers' geometric mean equals the geometric mean of their arithmetic and harmonic means. As noted above this relationship between the three Pythagorean means is not limited to n equals 1 or 2; there is a relationship for all n. However it should be noted that for n equals 1 all means are equal and for n equals 2 we have the above relationship between the means. For arbitrary n ? 2 we may generalize this formula, as noted above, by interpreting the third equation for the harmonic mean differently. The generalized relationship was already explained above. If one carefully observes the third equation one will notice it also works for n = 1. That is, it predicts the equivalence between the harmonic and geometric means but it falls short by not predicting the equivalence between the harmonic and arithmetic means. The general formula, which can be derived from the third formula for the harmonic mean by the reinterpretation as explained in relationship with other means, is Notice that for we have where we used the fact that the arithmetic mean evaluates to the same number independent of the order of the terms. This equation can be reduced to the original equation if we reinterpret this result in terms of the operators themselves. If we do this we get the symbolic equation because each function was evaluated at See also[edit] Statistics portal Mathematics portal Generalized mean Harmonic number Rate (mathematics) Weighted mean References[edit] ^ *Statistical Analysis, Ya-lun Chou, Holt International, 1969, ISBN 0030730953 ^ Mitchell, Douglas W., "More on spreads and non-arithmetic means," The Mathematical Gazette 88, March 2004, 142-144. ^ "Fairness Opinions: Common Errors and Omissions", The Handbook of Business Valuation and Intellectual Property Analysis, McGraw Hill, 2004. ISBN 0071429670 ^ Posamentier, Alfred S., and Salkind, Charles T., Challenging Problems in Geometry, second edition, Dover Publ. Co., 1996, p 172. ^ Voles, Roger, "Integer solutions of ," Mathematical Gazette 83, July 1999, 269–271. ^ Richinick, Jennifer, "The upside-down Pythagorean Theorem," Mathematical Gazette 92, July 2008, 313–;317. External links[edit] Weisstein, Eric W., "Harmonic Mean", MathWorld. Averages, Arithmetic and Harmonic Means at cut-the-knot v t e Statistics   Descriptive statistics Continuous data Location Mean (Arithmetic, Geometric, Harmonic) Median Mode Dispersion Range Standard deviation Coefficient of variation Percentile Interquartile range Shape Variance Skewness Kurtosis Moments L-moments Count data Index of dispersion Summary tables Grouped data Frequency distribution Contingency table Dependence Pearson product-moment correlation Rank correlation (Spearman's rho, Kendall's tau) Partial correlation Scatter plot Statistical graphics Bar chart Biplot Box plot Control chart Correlogram Fan chart Forest plot Histogram Pie chart Q–Q plot Run chart Scatter plot Stemplot Radar chart   Data collection Designing studies Effect size Standard error Statistical power Sample size determination Survey methodology Sampling Stratified sampling Opinion poll Questionnaire Controlled experiment Design of experiments Randomized experiment Random assignment Replication Blocking Factorial experiment Optimal design Uncontrolled studies Natural experiment Quasi-experiment Observational study   Statistical inference Statistical theory Sampling distribution Order statistic Scan statistic Sufficiency Completeness Exponential family Permutation test (Randomization test) Empirical distribution Bootstrap U statistic Efficiency Asymptotics Robustness Frequentist inference Unbiased estimator (Mean unbiased minimum variance, Median unbiased) Biased estimators (Maximum likelihood, Method of moments, Minimum distance, Density estimation) Confidence interval Testing hypotheses Power Parametric tests (Likelihood-ratio, Wald, Score) Specific tests Z (normal) Student's t-test F Goodness of fit (Chi-squared, G, Sample source, sample normality, Skewness & kurtosis Normality, Model comparison, Model quality) Signed-rank (1-sample, 2-sample, 1-way anova) Shapiro–Wilk Kolmogorov–Smirnov Bayesian inference Bayesian probability Prior Posterior Credible interval Bayes factor Bayesian estimator Maximum posterior estimator   Correlation and regression analysis Correlation Pearson product–moment correlation Partial correlation Confounding variable Coefficient of determination Regression analysis Errors and residuals Regression model validation Mixed effects models Simultaneous equations models MARS Linear regression Simple linear regression Ordinary least squares General linear model Bayesian regression Non-standard predictors Nonlinear regression Nonparametric Semiparametric Isotonic Robust Heteroscedasticity Homoscedasticity Generalized linear model Exponential families Logistic (Bernoulli) Binomial Poisson Partition of variance Analysis of variance (ANOVA) Analysis of covariance Multivariate ANOVA Degrees of freedom   Categorical, multivariate, time-series, or survival analysis Categorical data Cohen's kappa Contingency table Graphical model Log-linear model McNemar's test Multivariate statistics Multivariate regression Principal components Factor analysis Cluster analysis Classification Copulas Time series analysis General Decomposition Trend Stationarity Seasonal adjustment Exponential smoothing Cointegration Specific tests Granger causality Q-Statistic Durbin–Watson Time domain ACF PACF XCF ARMA model ARIMA model ARCH Vector autoregression Frequency domain Spectral density estimation Fourier analysis Survival analysis Survival function Kaplan–Meier Logrank test Failure rate Proportional hazards models Accelerated failure time model   Applications Biostatistics Bioinformatics Clinical trials & studies Epidemiology Medical statistics Engineering statistics Chemometrics Methods engineering Probabilistic design Process & Quality control Reliability System identification Social statistics Actuarial science Census Crime statistics Demography Econometrics National accounts Official statistics Population Psychometrics Spatial statistics Cartography Environmental statistics Geographic information system Geostatistics Kriging Category Portal Outline Index Retrieved from "http://en.wikipedia.org/w/index.php?title=Harmonic_mean&oldid=591099255" Categories: Means Navigation menu Personal tools Create account Log in Namespaces Article Talk Variants Views Read Edit View history Actions Search Navigation Main page Contents Featured content Current events Random article Donate to Wikipedia Interaction Help About Wikipedia Community portal Recent changes Contact page Tools What links here Related changes Upload file Special pages Permanent link Page information Data item Cite this page Print/export Create a book Download as PDF Printable version Languages ????????? Català ?e?tina Dansk Deutsch Eesti Espa?ol Esperanto Euskara ÝÇÑÓ? Français Galego ??? ?????? ????? ??????? Lietuvi? Magyar ?????????? Nederlands Norsk bokm?l Norsk nynorsk Piemontèis Polski Português Român? ??????? Sloven?ina Sloven??ina ?????? / srpski Srpskohrvatski / ?????????????? Suomi Svenska ????? Türkçe ÇÑÏæ Ti?ng Vi?t ?? Edit links This page was last modified on 17 January 2014 at 09:39. Text is available under the Creative Commons Attribution-ShareAlike License; additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy. Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc., a non-profit organization. Privacy policy About Wikipedia Disclaimers Contact Wikipedia Developers Mobile view